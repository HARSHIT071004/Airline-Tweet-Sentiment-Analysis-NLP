{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7c4013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt', download_dir=r'C:\\nltk_data')\n",
    "nltk.download('stopwords', download_dir=r'C:\\nltk_data')\n",
    "nltk.download('wordnet', download_dir=r'C:\\nltk_data')\n",
    "nltk.download('averaged_perceptron_tagger', download_dir=r'C:\\nltk_data')\n",
    "\n",
    "import nltk\n",
    "nltk.data.path.append(r'C:\\nltk_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39d0c4a0-626b-4f10-9b64-9b3a7d7f422b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Shape: (14640, 15)\n",
      "Data cleaned & preprocessed. Shape: (14640, 3)\n",
      "TF-IDF features extracted: (11712, 5000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8002\n",
      "Random Forest Accuracy: 0.7739\n",
      "SVM Accuracy: 0.7982\n",
      "\n",
      "Best Model: Logistic Regression | Accuracy: 0.8002\n",
      "TF-IDF vectorizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# NLP Sentiment Analysis Pipeline \n",
    "# ===============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import re\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# -------------------------------\n",
    "# Setup\n",
    "# -------------------------------\n",
    "np.random.seed(42)\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load Data\n",
    "# -------------------------------\n",
    "df = pd.read_csv('Tweets.csv')\n",
    "print(\"Dataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Preprocess Text\n",
    "# -------------------------------\n",
    "CUSTOM_STOPWORDS = {\"the\",\"a\",\"an\",\"is\",\"in\",\"on\",\"at\",\"to\",\"for\",\"and\",\"or\",\"but\",\"this\",\"that\",\"it\",\"i\",\"you\",\"we\",\"he\",\"she\",\"they\"}\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF]', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in CUSTOM_STOPWORDS]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Clean Data\n",
    "# -------------------------------\n",
    "df = df[['text', 'airline_sentiment']].dropna()\n",
    "sentiment_map = {'positive':2, 'neutral':1, 'negative':0}\n",
    "df['airline_sentiment'] = df['airline_sentiment'].map(sentiment_map)\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "print(\"Data cleaned & preprocessed. Shape:\", df.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. EDA \n",
    "# -------------------------------\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='airline_sentiment', data=df)\n",
    "plt.xticks([0,1,2], ['Negative','Neutral','Positive'])\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.savefig('outputs/sentiment_distribution.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Train-Test Split\n",
    "# -------------------------------\n",
    "X = df['cleaned_text']\n",
    "y = df['airline_sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. TF-IDF Feature Extraction\n",
    "# -------------------------------\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,3), min_df=2, max_df=0.95)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "print(\"TF-IDF features extracted:\", X_train_tfidf.shape)\n",
    "\n",
    "# ===============================\n",
    "# 7. Train & Evaluate Models\n",
    "# ===============================\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression Accuracy: {acc_lr:.4f}\")\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', xticklabels=['Neg','Neu','Pos'], yticklabels=['Neg','Neu','Pos'], cmap='Blues')\n",
    "plt.title('Confusion Matrix (Logistic Regression)')\n",
    "plt.savefig('outputs/confusion_matrix_logistic_regression.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {acc_rf:.4f}\")\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', xticklabels=['Neg','Neu','Pos'], yticklabels=['Neg','Neu','Pos'], cmap='Blues')\n",
    "plt.title('Confusion Matrix (Random Forest)')\n",
    "plt.savefig('outputs/confusion_matrix_random_forest.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {acc_svm:.4f}\")\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', xticklabels=['Neg','Neu','Pos'], yticklabels=['Neg','Neu','Pos'], cmap='Blues')\n",
    "plt.title('Confusion Matrix (SVM)')\n",
    "plt.savefig('outputs/confusion_matrix_svm.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Save Best Model & TF-IDF\n",
    "# -------------------------------\n",
    "best_acc = max(acc_lr, acc_rf, acc_svm)\n",
    "if best_acc == acc_lr:\n",
    "    best_model = lr_model\n",
    "    best_name = \"Logistic Regression\"\n",
    "elif best_acc == acc_rf:\n",
    "    best_model = rf_model\n",
    "    best_name = \"Random Forest\"\n",
    "else:\n",
    "    best_model = svm_model\n",
    "    best_name = \"SVM\"\n",
    "\n",
    "print(f\"\\nBest Model: {best_name} | Accuracy: {best_acc:.4f}\")\n",
    "joblib.dump(best_model, f'outputs/best_model_{best_name.lower().replace(\" \",\"_\")}.pkl')\n",
    "joblib.dump(tfidf, 'outputs/tfidf_vectorizer.pkl')\n",
    "print(\"TF-IDF vectorizer saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c899471e",
   "metadata": {},
   "source": [
    "The dataset contained 14,640 entries and 15 columns, but reducing it to 3 key features retained all essential sentiment information while improving processing efficiency.\n",
    "\n",
    "Cleaning steps like removing URLs, mentions, hashtags, punctuation, and custom stopwords significantly enhanced text quality and model performance.\n",
    "\n",
    "TF-IDF vectorization with 5,000 features effectively represented contextual relationships in the tweets, balancing detail and computational cost.\n",
    "\n",
    "Logistic Regression achieved the highest accuracy of 80.02%, showing that linear models are particularly effective for sparse, high-dimensional TF-IDF text data.\n",
    "\n",
    "SVM closely followed with 79.82% accuracy, while Random Forest lagged at 77.39%, indicating tree-based methods may be less suited for this type of data.\n",
    "\n",
    "The saved TF-IDF vectorizer and best-performing model ensure reproducibility and smooth deployment for real-world sentiment analysis tasks.\n",
    "\n",
    "The overall pipeline—from cleaning and feature extraction to model comparison and artifact saving—demonstrates a robust, production-ready NLP workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
